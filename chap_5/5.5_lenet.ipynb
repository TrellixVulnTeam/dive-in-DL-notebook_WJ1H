{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 本章开始正式介绍卷积神经网络（使用了卷积层的神经网络）\n",
    "\n",
    "# 比较非卷积 NN (以MLP为例)，MLP的几个明显缺陷是：\n",
    "# 1. 由于要将输入延展（将第i+1行放到第i行之后，最终形成一个行向量），\n",
    "# 故原本临近像素（i,j）和（i,j+1）之间的模式丢失，构成的行向量模式\n",
    "# 可能会导致Ｉnputs不能被正确识别．\n",
    "# 2. 1000x1000的图片与第一层隐藏层（假设隐藏单元的个数为256），经过全连接\n",
    "# 总的参数达到256,000,000，接近３Ｇ内存/显存．（即存储开销过大）\n",
    "\n",
    "# 卷积层改进：１．不延展输入图像，这样，图像像素在宽与高两个方向上的相关性得以保留\n",
    "# 2. 参数重复利用，这避免了参数过多的问题．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LeNet手写字符识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LeNet](./5.5_lenet.png)\n",
    "\n",
    "\n",
    "特点：\n",
    "1. 包括卷积模块　＋　fc模块\n",
    "2. 卷积模块：卷积层(无padding)，sigmoid和下采样层\n",
    "3. fc模块：flatten + fc(120) + fc(84) + fc(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import os\n",
    "from torch import nn, optim\n",
    "import sys\n",
    "sys.path.append('../d2lzh/')\n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "### 构建模型\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "root=os.path.join('..', 'Datasets', 'FashionMINST')\n",
    "\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size, root=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 修改　精度估算函数使其支持cuda tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        device = list(net.parameters())[0].device # 无指定，则使用net中的设置\n",
    "    \n",
    "    acc_sum, num = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, nn.Module): # net是nn.Module的子类\n",
    "                net.eval()   # 进入评估模式\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train()  # 回到训练模式\n",
    "            else:   # net不是Module的子类，而是自己构造的模型\n",
    "                if('is_training' in net.__code__.co_varnames):\n",
    "                    # 将这个参数设置为false\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            num += y.shape[0]\n",
    "    return acc_sum / num       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 对train_ch3作修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)                   # 网络模型\n",
    "    print('training on ', device)\n",
    "    loss = torch.nn.CrossEntropyLoss()   # 损失函数\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_sum, train_acc_sum, n, batch_count, start_time = 0.0, 0.0, 0, 0, time.time()\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            ls = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            ls.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_sum += ls.cpu().item()   # 损失值（每计算一个batch＿size就计算一次）\n",
    "            train_acc_sum  += (y_hat.argmax(dim=1) == y).sum().item()   # 训练精度（逐个样本计算）\n",
    "            n += y.shape[0]    # 总样本个数\n",
    "            batch_count += 1   # 所有的训练数据被分成了几个batch\n",
    "            \n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train_acc %.3f, test acc %.3f, time %.1f sec'\n",
    "             % (epoch + 1, train_loss_sum / batch_count,\n",
    "               train_acc_sum / n, test_acc, time.time() - start_time))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.2821, train_acc 0.894, test acc 0.882, time 1.8 sec\n",
      "epoch 2, loss 0.2795, train_acc 0.896, test acc 0.875, time 1.7 sec\n",
      "epoch 3, loss 0.2773, train_acc 0.897, test acc 0.885, time 1.8 sec\n",
      "epoch 4, loss 0.2753, train_acc 0.897, test acc 0.886, time 1.7 sec\n",
      "epoch 5, loss 0.2720, train_acc 0.899, test acc 0.882, time 1.7 sec\n",
      "epoch 6, loss 0.2711, train_acc 0.898, test acc 0.885, time 1.8 sec\n",
      "epoch 7, loss 0.2695, train_acc 0.900, test acc 0.883, time 1.7 sec\n",
      "epoch 8, loss 0.2701, train_acc 0.900, test acc 0.883, time 1.7 sec\n",
      "epoch 9, loss 0.2679, train_acc 0.899, test acc 0.883, time 1.7 sec\n",
      "epoch 10, loss 0.2666, train_acc 0.900, test acc 0.880, time 1.8 sec\n",
      "epoch 11, loss 0.2649, train_acc 0.900, test acc 0.877, time 1.8 sec\n",
      "epoch 12, loss 0.2621, train_acc 0.902, test acc 0.884, time 1.7 sec\n",
      "epoch 13, loss 0.2612, train_acc 0.903, test acc 0.884, time 1.7 sec\n",
      "epoch 14, loss 0.2614, train_acc 0.903, test acc 0.887, time 1.7 sec\n",
      "epoch 15, loss 0.2571, train_acc 0.904, test acc 0.888, time 1.8 sec\n",
      "epoch 16, loss 0.2570, train_acc 0.903, test acc 0.889, time 1.7 sec\n",
      "epoch 17, loss 0.2544, train_acc 0.906, test acc 0.889, time 1.7 sec\n",
      "epoch 18, loss 0.2552, train_acc 0.905, test acc 0.887, time 1.8 sec\n",
      "epoch 19, loss 0.2547, train_acc 0.904, test acc 0.890, time 1.8 sec\n",
      "epoch 20, loss 0.2509, train_acc 0.907, test acc 0.886, time 1.7 sec\n",
      "epoch 21, loss 0.2506, train_acc 0.906, test acc 0.890, time 1.7 sec\n",
      "epoch 22, loss 0.2493, train_acc 0.907, test acc 0.889, time 1.7 sec\n",
      "epoch 23, loss 0.2494, train_acc 0.907, test acc 0.885, time 1.7 sec\n",
      "epoch 24, loss 0.2483, train_acc 0.907, test acc 0.885, time 1.7 sec\n",
      "epoch 25, loss 0.2459, train_acc 0.909, test acc 0.889, time 1.7 sec\n",
      "epoch 26, loss 0.2469, train_acc 0.908, test acc 0.889, time 1.8 sec\n",
      "epoch 27, loss 0.2425, train_acc 0.909, test acc 0.890, time 1.7 sec\n",
      "epoch 28, loss 0.2429, train_acc 0.909, test acc 0.890, time 1.7 sec\n",
      "epoch 29, loss 0.2406, train_acc 0.910, test acc 0.891, time 1.8 sec\n",
      "epoch 30, loss 0.2393, train_acc 0.911, test acc 0.890, time 1.8 sec\n",
      "epoch 31, loss 0.2405, train_acc 0.910, test acc 0.886, time 1.7 sec\n",
      "epoch 32, loss 0.2372, train_acc 0.912, test acc 0.892, time 1.8 sec\n",
      "epoch 33, loss 0.2361, train_acc 0.912, test acc 0.890, time 1.8 sec\n",
      "epoch 34, loss 0.2363, train_acc 0.912, test acc 0.886, time 1.7 sec\n",
      "epoch 35, loss 0.2362, train_acc 0.912, test acc 0.894, time 1.8 sec\n",
      "epoch 36, loss 0.2339, train_acc 0.913, test acc 0.893, time 1.8 sec\n",
      "epoch 37, loss 0.2328, train_acc 0.913, test acc 0.895, time 1.8 sec\n",
      "epoch 38, loss 0.2317, train_acc 0.913, test acc 0.889, time 1.7 sec\n",
      "epoch 39, loss 0.2293, train_acc 0.913, test acc 0.891, time 1.7 sec\n",
      "epoch 40, loss 0.2295, train_acc 0.914, test acc 0.894, time 1.8 sec\n",
      "epoch 41, loss 0.2303, train_acc 0.913, test acc 0.895, time 1.7 sec\n",
      "epoch 42, loss 0.2286, train_acc 0.914, test acc 0.894, time 1.7 sec\n",
      "epoch 43, loss 0.2251, train_acc 0.915, test acc 0.894, time 1.7 sec\n",
      "epoch 44, loss 0.2245, train_acc 0.917, test acc 0.892, time 1.7 sec\n",
      "epoch 45, loss 0.2258, train_acc 0.915, test acc 0.886, time 1.7 sec\n",
      "epoch 46, loss 0.2241, train_acc 0.916, test acc 0.894, time 1.8 sec\n",
      "epoch 47, loss 0.2224, train_acc 0.917, test acc 0.895, time 1.8 sec\n",
      "epoch 48, loss 0.2206, train_acc 0.917, test acc 0.892, time 1.9 sec\n",
      "epoch 49, loss 0.2196, train_acc 0.918, test acc 0.893, time 1.7 sec\n",
      "epoch 50, loss 0.2185, train_acc 0.918, test acc 0.896, time 1.9 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 50\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
