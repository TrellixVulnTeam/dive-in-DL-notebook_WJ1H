{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AlexNet（２０１２），Alex Krizhevsky \n",
    "# 贡献：首个深度神经网络（８层）．它是浅层神经网络和深度神经网络的分界线。\n",
    "#      首次证明了学习到的特征可以超越手工设计的特征．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 早期图像分类任务的主要流程是：\n",
    "# 1. 获取图像数据集\n",
    "# ２．使用已有的　特征提取函数　生成图像的特征\n",
    "# 3. 使用机器学习模型对图像分类\n",
    "\n",
    "# 其中第三步是早期ＭＬ里面仅限的一步．当前ＣＶ研究者则认为，\n",
    "# ＣＶ中真正重要的是数据和特征．或者说，较干净的数据集和较有效的特征\n",
    "# 比机器学习模型的选择对分类的结果影响更大．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AlexNet](./5.6_alexnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### AlNet网络结构\n",
    "# 与LeNet的不同之处：\n",
    "# 1.使用了较大的卷积窗口11x11（这是因为两者的训练数据集图像尺寸不一样），后边使用较小尺寸的kernel\n",
    "# 2. 将sigmoid替换为简单的relu．一方面，sigmoid在input值较大/过小时，梯度更新值常常接近零，这不利于参数的训练．\n",
    "#   其二，sigmoid涉及幂运算，计算量较大．\n",
    "# 3.在fc-fc-fc的前两层使用了dropout防止过拟合\n",
    "# 4.使用了丰富的数据增广方式来增加数据量，防止过拟合．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:33:39.233829Z",
     "start_time": "2020-07-17T17:33:37.871899Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append('../d2lzh/')\n",
    "import d2lzh_pytorch as d2l \n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # layer 1\n",
    "            nn.Conv2d(1, 96, 11, 4), # in, out, k_s, stride, pad\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),  # kernel_size, stride\n",
    "            \n",
    "            # layer 2\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            \n",
    "            # layer 3            \n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # layer 4\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # layer 5\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            \n",
    "            # layer 6\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            # layer 7\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            # layer 8\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "#         print(feature.shape)      # 128x256x5x5, 所以layer6输入是256x5x5,不用考虑batchsize\n",
    "#         d2l.FlattenLayer(feature)\n",
    "        output = self.fc(feature.view(img.shape[0], -1)) # batch\n",
    "#         print(output.shape)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:33:43.522586Z",
     "start_time": "2020-07-17T17:33:43.252375Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 读取数据（此处加入了对数据进行增广的操作－resize）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:33:49.634142Z",
     "start_time": "2020-07-17T17:33:49.626393Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='../Datasets/FashionMINST/'):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(resize)) # 变换１\n",
    "    trans.append(torchvision.transforms.ToTensor())         # 变换２\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans) # 组合１/2等多种变换\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=False, transform=transform)\n",
    "    mnist_test  = torchvision.datasets.FashionMNIST(root=root, train=True, download=False, transform=transform)\n",
    "    \n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter  = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_iter, test_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:44:27.341274Z",
     "start_time": "2020-07-17T17:33:52.647235Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.6360, train_acc 0.760, test acc 0.847, time 62.4 sec\n",
      "epoch 2, loss 0.3368, train_acc 0.876, test acc 0.898, time 62.7 sec\n",
      "epoch 3, loss 0.2833, train_acc 0.895, test acc 0.907, time 63.0 sec\n",
      "epoch 4, loss 0.2530, train_acc 0.907, test acc 0.921, time 63.5 sec\n",
      "epoch 5, loss 0.2278, train_acc 0.915, test acc 0.920, time 63.4 sec\n",
      "epoch 6, loss 0.2151, train_acc 0.920, test acc 0.932, time 63.4 sec\n",
      "epoch 7, loss 0.1990, train_acc 0.926, test acc 0.933, time 63.3 sec\n",
      "epoch 8, loss 0.1869, train_acc 0.930, test acc 0.938, time 63.4 sec\n",
      "epoch 9, loss 0.1749, train_acc 0.935, test acc 0.942, time 63.6 sec\n",
      "epoch 10, loss 0.1616, train_acc 0.939, test acc 0.953, time 63.2 sec\n"
     ]
    }
   ],
   "source": [
    "# 做数据增广（把input尺寸由28x28放大到224x224）\n",
    "batch_size = 128\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.001, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 不做数据增广(失败了，因为输入尺寸太小，而且中间还做了三次maxpooling)\n",
    "# batch_size = 128\n",
    "# train_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
    "\n",
    "# lr, num_epochs = 0.001, 10\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
