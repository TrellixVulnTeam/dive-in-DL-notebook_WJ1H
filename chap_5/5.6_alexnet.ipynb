{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AlexNet（２０１２），Alex Krizhevsky \n",
    "# 贡献：首个深度神经网络（８层）．它是浅层神经网络和深度神经网络的分界线。\n",
    "#       首次证明了学习到的特征可以超越手工设计的特征．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 早期图像分类任务的主要流程是：\n",
    "# 1. 获取图像数据集\n",
    "# ２．使用已有的　特征提取函数　生成图像的特征\n",
    "# 3. 使用机器学习模型对图像分类\n",
    "\n",
    "# 其中第三步是早期ＭＬ里面仅限的一步．当前ＣＶ研究者则认为，\n",
    "# ＣＶ中真正重要的是数据和特征．或者说，较干净的数据集和较有效的特征\n",
    "# 比机器学习模型的选择对分类的结果影响更大．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AlexNet](./5.6_alexnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### AlNet网络结构\n",
    "# 与LeNet的不同之处：\n",
    "# 1.使用了较大的卷积窗口11x11（这是因为两者的训练数据集图像尺寸不一样），后边使用较小尺寸的kernel\n",
    "# 2. 将sigmoid替换为简单的relu．一方面，sigmoid在input值较大/过小时，梯度更新值常常接近零，这不利于参数的训练．\n",
    "#   其二，sigmoid涉及幂运算，计算量较大．\n",
    "# 3.在fc-fc-fc的前两层使用了dropout防止过拟合\n",
    "# 4.使用了丰富的数据增广方式来增加数据量，防止过拟合．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append('../d2lzh/')\n",
    "import d2lzh_pytorch as d2l \n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # layer 1\n",
    "            nn.Conv2d(1, 96, 11, 4), # in, out, k_s, stride, pad\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),  # kernel_size, stride\n",
    "            \n",
    "            # layer 2\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            \n",
    "            # layer 3            \n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # layer 4\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # layer 5\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            \n",
    "            # layer 6\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            # layer 7\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            # layer 8\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "#         print(feature.shape)      # 128x256x5x5, 所以layer6输入是256x5x5,不用考虑batchsize\n",
    "#         d2l.FlattenLayer(feature)\n",
    "        output = self.fc(feature.view(img.shape[0], -1)) # batch\n",
    "#         print(output.shape)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 读取数据（此处加入了对数据进行增广的操作－resize）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='../Datasets/FashionMINST/'):\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(resize)) # 变换１\n",
    "    trans.append(torchvision.transforms.ToTensor())         # 变换２\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans) # 组合１/2等多种变换\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=False, transform=transform)\n",
    "    mnist_test  = torchvision.datasets.FashionMNIST(root=root, train=True, download=False, transform=transform)\n",
    "    \n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter  = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_iter, test_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 做数据增广（把input尺寸由28x28放大到224x224）\n",
    "batch_size = 128\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.001, 10\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 不做数据增广(失败了，因为输入尺寸太小，而且中间还做了三次maxpooling)\n",
    "# batch_size = 128\n",
    "# train_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
    "\n",
    "# lr, num_epochs = 0.001, 10\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
