{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import sys\n",
    "sys.path.append('../d2lzh/')\n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置demo是为了用部分数据去训练模型（原数据太多）\n",
    "# 使用500张图片进行测试，50张图片进行验证\n",
    "demo = False\n",
    "data_dir = '../Datasets/kaggle_dog/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 整理数据集\n",
    "\n",
    "def reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        将每一类狗狗的照片归类这类狗狗的文件夹下。\n",
    "    Args:\n",
    "        valid_ratio: 验证集中，每类狗的样本数与原始数据集中包含狗的样本数最少的那一类的样本数之比。\n",
    "        idx_label: 字典结构。\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # 找出包含狗的样本数最少的那一类\n",
    "    min_n_train_per_label = (\n",
    "        collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1]\n",
    "    )\n",
    "    \n",
    "    # 验证集中每类狗的样本数\n",
    "    n_valid_per_label = math.floor(min_n_train_per_label * valid_ratio)\n",
    "    label_count = {}\n",
    "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
    "        idx = train_file.split('.')[0]\n",
    "        label = idx_label[idx]\n",
    "        d2l.mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
    "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                   os.path.join(data_dir, input_dir, 'train_valid', label))\n",
    "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
    "            d2l.mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file), \n",
    "                       os.path.join(data_dir, input_dir, 'valid', label))\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        \n",
    "        else:\n",
    "            d2l.mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
    "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
    "                       os.path.join(data_dir, input_dir, 'train', label))\n",
    "\n",
    "def reorg_dog_data(data_dir, label_dir, train_dir, test_dir, input_dir, valid_ratio):\n",
    "    \n",
    "    with open(os.path.join(data_dir, label_dir), 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "        tokens = [l.rstrip().split(',') for l in lines]\n",
    "        idx_label = dict(((idx, label) for idx, label in tokens))\n",
    "    \n",
    "    reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label)\n",
    "    \n",
    "    d2l.mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
    "    \n",
    "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
    "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
    "                   os.path.join(data_dir, input_dir, 'test', 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "      \n",
    "if demo:\n",
    "    input_dir, batch_size = 'train_valid_test_tiny', 1\n",
    "else:\n",
    "    label_file, train_dir, test_dir = 'labels.csv', 'train', 'test'\n",
    "    input_dir, batch_size, valid_ratio = 'train_valid_test', 16, 0.1\n",
    "#     reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 图像增广\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(224, \n",
    "                                                 scale=(0.08, 1.0),\n",
    "                                                ratio=(3.0/4.0, 4.0/3.0)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ColorJitter(brightness=0.4, \n",
    "                                          contrast=0.4,\n",
    "                                          saturation=0.4),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225],\n",
    "        ),\n",
    "        \n",
    "    ])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(256),\n",
    "        torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 读取数据集\n",
    "\n",
    "from torchvision.datasets import ImageFolder as IF\n",
    "from torch.utils.data import DataLoader as DL\n",
    "\n",
    "train_data_path = os.path.join(data_dir, input_dir, 'train')\n",
    "# train_data = IF(train_data_path, transform=transform_train)\n",
    "\n",
    "valid_data_path = os.path.join(data_dir, input_dir, 'valid')\n",
    "# valid_data = IF(valid_data_path, transform=transform_train)\n",
    "\n",
    "train_valid_data_path = os.path.join(data_dir, input_dir, 'train_valid')\n",
    "# train_valid_data = IF(train_valid_data_path, transform=transform_train)\n",
    "\n",
    "test_data_path = os.path.join(data_dir, input_dir, test_dir)\n",
    "test_data = IF(test_data_path, transform=transform_test)\n",
    "\n",
    "# 封装\n",
    "# train_iter = DL(train_data, batch_size, shuffle=True)\n",
    "# valid_iter = DL(valid_data, batch_size, shuffle=True)\n",
    "# train_valid_iter = DL(train_valid_data, batch_size, shuffle=True)\n",
    "test_iter = DL(test_data, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 定义模型\n",
    "# 由于dog数据集是ImageNet的子集，所有采用fine tuning的思想来进行迁移学习\n",
    "\n",
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "\n",
    "pretrained_net = models.resnet34(pretrained=True) # 下载模型(如果为True)\n",
    "\n",
    "# print(pretrained_net)\n",
    "# print(pretrained_net.fc)\n",
    "pretrained_net.fc = nn.Linear(512, 120)  # 参数已经完成初始化，但其他层的参数依旧保持不变\n",
    "# print(pretrained_net.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 更改模型的学习率（前面参数的学习率较低、最后一层参数的学习率较高）\n",
    "\n",
    "# 先列出参数\n",
    "output_params = list(map(id, pretrained_net.fc.parameters()))\n",
    "# print(output_params)\n",
    "\n",
    "# 过滤出其他参数\n",
    "feature_params = filter(lambda p: id(p) not in output_params, pretrained_net.parameters())\n",
    "# print(feature_params)\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = optim.SGD([\n",
    "        {'params': feature_params},\n",
    "        {'params': pretrained_net.fc.parameters(), 'lr':lr * 10}],\n",
    "        lr=lr, weight_decay=0.001,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 定义训练函数\n",
    "\n",
    "def train(net, train_iter, valid_iter, loss, optimizer, num_epochs, device):\n",
    "    \n",
    "    net = net.to(device)\n",
    "    print(\"training on:\", device)\n",
    "    batch_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, bs = 0.0, 0.0, 0        \n",
    "        start = time.time()\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            bs += y.shape[0]\n",
    "            batch_count += 1\n",
    "            \n",
    "        if valid_iter is not None:\n",
    "            valid_acc = d2l.evaluate_accuracy(valid_iter, net)\n",
    "            acc_str = (\"train acc %.4f, valid acc %.4f,\" \n",
    "                        % (train_acc_sum / bs, valid_acc))\n",
    "        else:\n",
    "            acc_str = (\"train acc %.4f,\" % (train_acc_sum / bs))\n",
    "            \n",
    "        print(\"epoch %d, train loss %.3f,\" % (epoch + 1, train_l_sum / batch_count) \n",
    "              + acc_str + \"time %.2f\" % (time.time() - start))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 开始训练(暂时先不测试)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 200\n",
    "\n",
    "# train(pretrained_net, train_iter, valid_iter, loss, optimizer, num_epochs, device)\n",
    "\n",
    "# 保存\n",
    "# PATH = \"./pretrained_resnet34_my.pth\"\n",
    "# torch.save(pretrained_net.state_dict(), PATH)\n",
    "\n",
    "#　加载\n",
    "# model = models.resnet34(pretrained=False) \n",
    "# model.fc = nn.Linear(512, 120)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 进入测试环节（用所有训练集训练，所有的测试集进行测试）\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# #　加载\n",
    "# model = models.resnet34(pretrained=False) \n",
    "# model.fc = nn.Linear(512, 120)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.state_dict()\n",
    "\n",
    "# train(pretrained_net, train_valid_iter, None, loss, optimizer, num_epochs, device)\n",
    "\n",
    "# 保存\n",
    "PATH = \"./pretrained_resnet34_my.pth\"\n",
    "# torch.save(pretrained_net.state_dict(), PATH)\n",
    "\n",
    "#　加载\n",
    "model = models.resnet34(pretrained=False) \n",
    "model.fc = nn.Linear(512, 120)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "# model.state_dict()\n",
    "\n",
    "preds = []\n",
    "for X, _ in test_iter:\n",
    "    y_hat = model(X)\n",
    "    preds.extend(y_hat.cpu())   # 将每个样本的预测值计算出来。预测结果如 0,1,2,...,9\n",
    "    \n",
    "\n",
    "print(preds[0])\n",
    "\n",
    "ids = sorted(os.listdir(os.path.join(data_dir, input_dir, 'test/unknown')))\n",
    "with open(\"submission.csv\", 'w') as f:\n",
    "    f.write('id,' + \",\".join(train_valid_data.classes) + '\\n')\n",
    "    for i, output in zip(ids, preds):\n",
    "        f.write(i.split('.')[0] + ',' + ','.join([str(num) for num in output]) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
